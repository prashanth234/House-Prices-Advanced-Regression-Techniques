{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "House prices prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dnpz12wthcsm"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas_profiling as pp\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "# Machine learning libraries\n",
        "from sklearn.linear_model import LogisticRegression, SGDRegressor, BayesianRidge\n",
        "from sklearn.svm import SVR, LinearSVR\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NUtYFiW5toU"
      },
      "source": [
        "# load data\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXqwAURtk5Be"
      },
      "source": [
        "# sns.distplot(train_df['SalePrice'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbipcAH8e1Tz",
        "outputId": "c1a75b76-6bd9-4b60-de0f-f9f32ac12471",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# skewness is a measures of distortion from the normal distribution\n",
        "print(\"skewness: %f\" %train_df['SalePrice'].skew())\n",
        "# kurtosis is used to measure outilers\n",
        "print(\"kurtosis: %f\" %train_df['SalePrice'].kurt())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "skewness: 1.882876\n",
            "kurtosis: 6.536282\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imEqBOmBr3aP"
      },
      "source": [
        "# histogram of tagert and norm\n",
        "# from scipy import stats\n",
        "# sns.distplot(train_df['SalePrice'], fit=stats.norm);\n",
        "# fig = plt.figure()\n",
        "# res = stats.probplot(train_df['SalePrice'], plot=plt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tehu_q1m5W4O"
      },
      "source": [
        "classifiers = [\n",
        "                # LogisticRegression(max_iter=500),\n",
        "                # SGDRegressor(),\n",
        "                BayesianRidge(),\n",
        "                SVR(),\n",
        "                LinearSVR(),\n",
        "                RandomForestRegressor(),\n",
        "                DecisionTreeRegressor(),\n",
        "                KNeighborsRegressor()\n",
        "              ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gaqbxt_y6WhW",
        "outputId": "fa776f3b-cfe4-44e9-e14f-ece6bc285a50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Parameters\n",
        "# Cateogorical values have similar values\n",
        "coulumns_more_similar_values = ['Id', 'Heating', 'BsmtCond', 'CentralAir', 'Electrical', 'Functional',\n",
        "'Street', 'LandContour', 'Utilities', 'LandSlope', 'Condition1', 'Condition2', 'RoofMatl',\n",
        "'ExterCond','BsmtFinType2', 'GarageQual', 'GarageCond', \n",
        "'PavedDrive', 'SaleType', 'SaleCondition', 'Neighborhood']\n",
        "\n",
        "# cloumns have more than 15% of missing data\n",
        "missing_data_cols1 = ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', 'LotFrontage']\n",
        "\n",
        "missing_data_cols2 = [ 'GarageCond', 'GarageType', 'MasVnrArea', 'MasVnrType', 'GarageYrBlt', 'GarageFinish', 'GarageQual', 'BsmtUnfSF', 'Utilities',\n",
        "'BsmtExposure', 'BsmtFinType2', 'BsmtFinType1', 'BsmtCond' ,'BsmtQual', 'BsmtHalfBath', 'BsmtFullBath']\n",
        "\n",
        "#Many zeros and not much corelation with target\n",
        "many_zeros = ['BsmtFinSF2', 'LowQualFinSF', 'BsmtHalfBath', 'KitchenAbvGr', \n",
        "'3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'EnclosedPorch']\n",
        "\n",
        "similar_features = ['TotRmsAbvGrd', 'GarageCars', 'TotalBsmtSF', 'Neighborhood']\n",
        "\n",
        "drop_cols = missing_data_cols1\n",
        "drop_cols.append('Id')\n",
        "print(len(drop_cols))\n",
        "target = 'SalePrice'\n",
        "has_cv = True\n",
        "split_size = 0.8 if has_cv else 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc7akeVs311_"
      },
      "source": [
        "percentage = (train_df.isnull().sum()).sort_values(ascending = False)\n",
        "# percentage.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFKydC8oAGdL"
      },
      "source": [
        "# train_df[drop_cols].\n",
        "# val = 'BsmtFinSF2'\n",
        "# data = pd.concat([train_df[target], train_df[val]], axis = 1)\n",
        "# data.plot.scatter(x=val, y=target, ylim=(0, 800000))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUuyIqD1H-GJ"
      },
      "source": [
        "# val = 'CentralAir'\n",
        "# data = pd.concat([train_df[target], train_df[val]], axis = 1)\n",
        "# fig = sns.boxplot(x=val, y=target, data=data)\n",
        "# fig.axis(ymin=0, ymax=800000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nxDbDmh9CTe"
      },
      "source": [
        "# corr_max = train_df[many_zeros].corr()\n",
        "# sns.heatmap(corr_max, vmax=.8, square=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8U4tK7vK6gn"
      },
      "source": [
        "# cols_temp = many_zeros +  missing_data_cols\n",
        "# corrmat = train_df.drop(cols_temp, axis=1).corr()\n",
        "# #saleprice correlation matrix\n",
        "# k = 10 #number of variables for heatmap\n",
        "# cols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\n",
        "# cm = np.corrcoef(train_df[cols].values.T)\n",
        "# sns.set(font_scale=1.25)\n",
        "# hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-f8Tb6haawsJ"
      },
      "source": [
        "train_mod_df = train_df.drop(drop_cols, axis=1)\n",
        "test_mod_df = test_df.drop(drop_cols, axis=1)\n",
        "\n",
        "combine = [train_mod_df, test_mod_df]\n",
        "from scipy.stats import skew\n",
        "\n",
        "for data in combine:\n",
        "  skewed_feats = data.select_dtypes(exclude=['object']).apply(lambda x: skew(x.dropna())) #compute skewness\n",
        "  skewed_feats = skewed_feats[skewed_feats > 0.75]\n",
        "  skewed_feats = skewed_feats.index\n",
        "\n",
        "  data[skewed_feats] = np.log1p(data[skewed_feats])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1EhyNz4HzuT"
      },
      "source": [
        "combine = [train_mod_df, test_mod_df]\n",
        "\n",
        "for data in combine:\n",
        "  data['BsmtFinSF1'].fillna(train_mod_df['BsmtFinSF1'].dropna().mean(), inplace=True)\n",
        "  data['GarageArea'].fillna(train_mod_df['GarageArea'].dropna().mean(), inplace=True)\n",
        "  data['TotalBsmtSF'].fillna(train_mod_df['TotalBsmtSF'].dropna().mode()[0], inplace=True)\n",
        "  data['GarageCars'].fillna(train_mod_df['GarageCars'].dropna().mode()[0], inplace=True)\n",
        "  data['TotalArea'] = data['TotalBsmtSF'] + data['1stFlrSF'] + data['2ndFlrSF'] + data['GrLivArea'] +data['GarageArea']\n",
        "\n",
        "  data['Bathrooms'] = data['FullBath'] + data['HalfBath']*0.5 \n",
        "\n",
        "  data['Year average']= (data['YearRemodAdd']+data['YearBuilt'])/2\n",
        "\n",
        "  cols_numeric = list(data.select_dtypes(exclude=['object']).columns)\n",
        "  for col in cols_numeric:\n",
        "    data[col].fillna(0, inplace=True)\n",
        "  \n",
        "  cols_object = list(data.select_dtypes(include=['object']).columns)\n",
        "  for col in cols_object:\n",
        "    freq = train_mod_df[col].dropna().mode()[0]\n",
        "    data[col].fillna(freq, inplace=True)\n",
        "    # data[col] = data[col].astype('category').cat.codes\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGYC8mpyiTDR",
        "outputId": "629b1f88-b732-4c25-9190-5b58d5b9eb5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "train_dum_shape = train_mod_df.shape[0]\n",
        "c = pd.concat((train_mod_df, test_mod_df), sort=False).reset_index(drop=True) \n",
        "dummies = pd.get_dummies(c)\n",
        "train_mod_df = dummies[:train_dum_shape]\n",
        "test_mod_df = dummies[train_dum_shape:]\n",
        "print(f'train shape after dummies {train_mod_df.shape}')\n",
        "print(f'test shape after dummies {test_mod_df.shape}')\n",
        "percentage = (test_mod_df.isnull().sum()).sort_values(ascending = False)\n",
        "percentage.head(15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train shape after dummies (1460, 273)\n",
            "test shape after dummies (1459, 273)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SalePrice                1459\n",
              "SaleCondition_Partial       0\n",
              "Condition1_PosN             0\n",
              "Neighborhood_Timber         0\n",
              "Neighborhood_Veenker        0\n",
              "Condition1_Artery           0\n",
              "Condition1_Feedr            0\n",
              "Condition1_Norm             0\n",
              "Condition1_PosA             0\n",
              "Condition1_RRAe             0\n",
              "Neighborhood_ClearCr        0\n",
              "Condition1_RRAn             0\n",
              "Condition1_RRNe             0\n",
              "Condition1_RRNn             0\n",
              "Condition2_Artery           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOajtyXJK6S7"
      },
      "source": [
        "# fig = plt.figure(figsize=(15, 15))\n",
        "# col1 = 'TotRmsAbvGrd'\n",
        "# col2 = target\n",
        "# val = 13\n",
        "# print(len(train_mod_df[col1]))\n",
        "# ax1 = plt.subplot2grid((3, 2), (0, 0))\n",
        "# plt.scatter(x=train_df[col1], y = train_df[col2])\n",
        "# plt.axvline(x=val, color='r', linestyle='-')\n",
        "# plt.title(col1+col2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8gXEeL2GTSt",
        "outputId": "4b80e64c-17e3-4856-d255-92eea2d46463",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "train_mod_df['GrLivArea'].sort_values(ascending=False).head(2)\n",
        "train_mod_df['TotalBsmtSF'].sort_values(ascending=False).head(1)\n",
        "train_mod_df['1stFlrSF'].sort_values(ascending=False).head(1)\n",
        "train_mod_df['GarageArea'].sort_values(ascending=False).head(4)\n",
        "train_mod_df['TotRmsAbvGrd'].sort_values(ascending=False).head(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "635    14.0\n",
              "Name: TotRmsAbvGrd, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_eobv7cHBDv",
        "outputId": "4ce25239-4886-406a-b427-bfa4248bd09b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "pos = [1298, 593, 581, 1190, 1061, 635]\n",
        "train_mod_df.drop(train_mod_df.index[pos], inplace=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGXEUevp8Kjb"
      },
      "source": [
        "# Get only sepcific columns\n",
        "def process_data (data, test=False) :\n",
        "  # Data normalization and converting pandas to numpy array\n",
        "  # temp = data.select_dtypes(exclude=['object'])\n",
        "  temp = data\n",
        "  temp = temp.drop(target, axis=1)\n",
        "\n",
        "  # temp = pd.get_dummies(temp)\n",
        "  # temp.fillna(value=0, inplace=True)\n",
        "  temp = temp.to_numpy()\n",
        "  # temp = temp / np.amax(temp, axis=0)\n",
        "\n",
        "  if (test):\n",
        "    return temp\n",
        "  else:\n",
        "    labels = data[target]\n",
        "    return temp, labels.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0dthKT-BxDx",
        "outputId": "bc67feec-6f8a-4083-ea43-efc79e53edd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Total data\n",
        "train_data_input, train_data_label = process_data(train_mod_df)\n",
        "test_data_input = process_data(test_mod_df, True)\n",
        "print(f'Total Train Input Shape : {train_data_input.shape}')\n",
        "print(f'Total Train Label Shape : {train_data_label.shape}')\n",
        "print(f'Total Test Input Shape : {test_data_input.shape}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Train Input Shape : (1454, 272)\n",
            "Total Train Label Shape : (1454,)\n",
            "Total Test Input Shape : (1459, 272)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WsGnF9YC3mR",
        "outputId": "076d4841-cef8-4f26-9b39-bc9581614305",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# Split data\n",
        "split = int(len(train_data_input)*split_size)\n",
        "# Train split\n",
        "train_input = train_data_input[:split]\n",
        "train_label = train_data_label[:split]\n",
        "# CV split\n",
        "cv_input = train_data_input[split:]\n",
        "cv_label = train_data_label[split:]\n",
        "\n",
        "print(f'Train Input Shape : {train_input.shape}')\n",
        "print(f'Train Label Shape : {train_label.shape}')\n",
        "print(f'CV Input Shape : {cv_input.shape}')\n",
        "print(f'CV label Shape : {cv_label.shape}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Input Shape : (1163, 272)\n",
            "Train Label Shape : (1163,)\n",
            "CV Input Shape : (291, 272)\n",
            "CV label Shape : (291,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOn2wT5BQZ20"
      },
      "source": [
        "def get_scores(cv):\n",
        "  train_scores = []\n",
        "  test_scores = []\n",
        "  for clf in classifiers:\n",
        "    clf.fit(train_input, train_label)\n",
        "    pred = clf.predict(train_input)\n",
        "    tscore = np.round(math.sqrt(mean_squared_error(train_label, pred)), 4)\n",
        "    train_scores.append(str(tscore))\n",
        "    if (cv) :\n",
        "      pred = clf.predict(cv_input)\n",
        "      cvscore = np.round(math.sqrt(mean_squared_error(cv_label, pred)), 4)\n",
        "      test_scores.append(str(cvscore))\n",
        "    else:\n",
        "      test_scores.append(str(tscore))\n",
        "  return train_scores, test_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LLPGEHERF_r"
      },
      "source": [
        "# train_scores, test_scores = get_scores(has_cv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQ6_9xRNavoQ",
        "outputId": "fa8ecbd9-325c-4795-ff54-6bf11ac666d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# model = tf.keras.Sequential([\n",
        "#     tf.keras.layers.Dense(150, input_shape=[train_input.shape[1]], activation=\"relu\"),\n",
        "#     tf.keras.layers.Dropout(0.2),\n",
        "#     tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "#     tf.keras.layers.Dense(1)\n",
        "# ])\n",
        "# model.summary()\n",
        "\n",
        "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "# model.compile(optimizer=optimizer, loss='mse')\n",
        "\n",
        "# if has_cv:\n",
        "#   history = model.fit(train_input, train_label, validation_data=(cv_input, cv_label), epochs=500, verbose=2)\n",
        "# else:\n",
        "#   history = model.fit(train_input, train_label, epochs=500, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 150)               40950     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 100)               15100     \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 56,151\n",
            "Trainable params: 56,151\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "37/37 - 0s - loss: 62555.8867 - val_loss: 157.4976\n",
            "Epoch 2/500\n",
            "37/37 - 0s - loss: 222.5246 - val_loss: 19.6739\n",
            "Epoch 3/500\n",
            "37/37 - 0s - loss: 71.5441 - val_loss: 3.4738\n",
            "Epoch 4/500\n",
            "37/37 - 0s - loss: 33.7639 - val_loss: 9.5909\n",
            "Epoch 5/500\n",
            "37/37 - 0s - loss: 24.5985 - val_loss: 6.4991\n",
            "Epoch 6/500\n",
            "37/37 - 0s - loss: 21.9708 - val_loss: 3.8873\n",
            "Epoch 7/500\n",
            "37/37 - 0s - loss: 17.0398 - val_loss: 3.2001\n",
            "Epoch 8/500\n",
            "37/37 - 0s - loss: 14.6101 - val_loss: 1.5853\n",
            "Epoch 9/500\n",
            "37/37 - 0s - loss: 12.7890 - val_loss: 7.2339\n",
            "Epoch 10/500\n",
            "37/37 - 0s - loss: 12.3975 - val_loss: 6.4023\n",
            "Epoch 11/500\n",
            "37/37 - 0s - loss: 12.4680 - val_loss: 15.6861\n",
            "Epoch 12/500\n",
            "37/37 - 0s - loss: 9.8203 - val_loss: 3.3799\n",
            "Epoch 13/500\n",
            "37/37 - 0s - loss: 8.5077 - val_loss: 4.6830\n",
            "Epoch 14/500\n",
            "37/37 - 0s - loss: 8.5220 - val_loss: 3.5723\n",
            "Epoch 15/500\n",
            "37/37 - 0s - loss: 5.7463 - val_loss: 1.7740\n",
            "Epoch 16/500\n",
            "37/37 - 0s - loss: 7.3693 - val_loss: 5.0544\n",
            "Epoch 17/500\n",
            "37/37 - 0s - loss: 6.6866 - val_loss: 0.9070\n",
            "Epoch 18/500\n",
            "37/37 - 0s - loss: 5.7865 - val_loss: 1.8513\n",
            "Epoch 19/500\n",
            "37/37 - 0s - loss: 5.4571 - val_loss: 2.4345\n",
            "Epoch 20/500\n",
            "37/37 - 0s - loss: 5.4072 - val_loss: 1.8225\n",
            "Epoch 21/500\n",
            "37/37 - 0s - loss: 5.2016 - val_loss: 0.5120\n",
            "Epoch 22/500\n",
            "37/37 - 0s - loss: 6.2538 - val_loss: 3.6614\n",
            "Epoch 23/500\n",
            "37/37 - 0s - loss: 4.9284 - val_loss: 4.1831\n",
            "Epoch 24/500\n",
            "37/37 - 0s - loss: 4.7865 - val_loss: 2.3655\n",
            "Epoch 25/500\n",
            "37/37 - 0s - loss: 4.0978 - val_loss: 2.9022\n",
            "Epoch 26/500\n",
            "37/37 - 0s - loss: 3.7589 - val_loss: 6.5285\n",
            "Epoch 27/500\n",
            "37/37 - 0s - loss: 3.2120 - val_loss: 5.8365\n",
            "Epoch 28/500\n",
            "37/37 - 0s - loss: 3.4818 - val_loss: 5.3902\n",
            "Epoch 29/500\n",
            "37/37 - 0s - loss: 2.7688 - val_loss: 3.3556\n",
            "Epoch 30/500\n",
            "37/37 - 0s - loss: 3.2629 - val_loss: 2.4360\n",
            "Epoch 31/500\n",
            "37/37 - 0s - loss: 2.6846 - val_loss: 4.5438\n",
            "Epoch 32/500\n",
            "37/37 - 0s - loss: 2.5944 - val_loss: 2.7572\n",
            "Epoch 33/500\n",
            "37/37 - 0s - loss: 2.8283 - val_loss: 0.9713\n",
            "Epoch 34/500\n",
            "37/37 - 0s - loss: 2.2435 - val_loss: 3.8266\n",
            "Epoch 35/500\n",
            "37/37 - 0s - loss: 2.3561 - val_loss: 2.6073\n",
            "Epoch 36/500\n",
            "37/37 - 0s - loss: 2.3623 - val_loss: 3.1261\n",
            "Epoch 37/500\n",
            "37/37 - 0s - loss: 2.4939 - val_loss: 0.6850\n",
            "Epoch 38/500\n",
            "37/37 - 0s - loss: 2.5508 - val_loss: 2.8361\n",
            "Epoch 39/500\n",
            "37/37 - 0s - loss: 2.1796 - val_loss: 2.4293\n",
            "Epoch 40/500\n",
            "37/37 - 0s - loss: 2.5848 - val_loss: 2.0587\n",
            "Epoch 41/500\n",
            "37/37 - 0s - loss: 2.1400 - val_loss: 4.7852\n",
            "Epoch 42/500\n",
            "37/37 - 0s - loss: 1.9023 - val_loss: 2.9522\n",
            "Epoch 43/500\n",
            "37/37 - 0s - loss: 2.2301 - val_loss: 4.4763\n",
            "Epoch 44/500\n",
            "37/37 - 0s - loss: 2.1532 - val_loss: 4.1422\n",
            "Epoch 45/500\n",
            "37/37 - 0s - loss: 1.5674 - val_loss: 4.1966\n",
            "Epoch 46/500\n",
            "37/37 - 0s - loss: 1.8037 - val_loss: 3.3951\n",
            "Epoch 47/500\n",
            "37/37 - 0s - loss: 1.7348 - val_loss: 5.8607\n",
            "Epoch 48/500\n",
            "37/37 - 0s - loss: 2.0889 - val_loss: 0.3633\n",
            "Epoch 49/500\n",
            "37/37 - 0s - loss: 1.7968 - val_loss: 2.2703\n",
            "Epoch 50/500\n",
            "37/37 - 0s - loss: 1.5892 - val_loss: 2.3312\n",
            "Epoch 51/500\n",
            "37/37 - 0s - loss: 1.5232 - val_loss: 4.7167\n",
            "Epoch 52/500\n",
            "37/37 - 0s - loss: 1.7558 - val_loss: 2.0560\n",
            "Epoch 53/500\n",
            "37/37 - 0s - loss: 1.4827 - val_loss: 2.3380\n",
            "Epoch 54/500\n",
            "37/37 - 0s - loss: 1.4558 - val_loss: 3.0999\n",
            "Epoch 55/500\n",
            "37/37 - 0s - loss: 1.7618 - val_loss: 5.5264\n",
            "Epoch 56/500\n",
            "37/37 - 0s - loss: 1.4684 - val_loss: 2.1858\n",
            "Epoch 57/500\n",
            "37/37 - 0s - loss: 1.3884 - val_loss: 2.5080\n",
            "Epoch 58/500\n",
            "37/37 - 0s - loss: 1.4890 - val_loss: 1.1555\n",
            "Epoch 59/500\n",
            "37/37 - 0s - loss: 1.2514 - val_loss: 4.3414\n",
            "Epoch 60/500\n",
            "37/37 - 0s - loss: 1.4803 - val_loss: 6.7381\n",
            "Epoch 61/500\n",
            "37/37 - 0s - loss: 1.3608 - val_loss: 4.7448\n",
            "Epoch 62/500\n",
            "37/37 - 0s - loss: 1.3018 - val_loss: 3.3993\n",
            "Epoch 63/500\n",
            "37/37 - 0s - loss: 1.1155 - val_loss: 5.5790\n",
            "Epoch 64/500\n",
            "37/37 - 0s - loss: 1.3495 - val_loss: 4.9666\n",
            "Epoch 65/500\n",
            "37/37 - 0s - loss: 1.1042 - val_loss: 4.2750\n",
            "Epoch 66/500\n",
            "37/37 - 0s - loss: 1.1745 - val_loss: 4.7496\n",
            "Epoch 67/500\n",
            "37/37 - 0s - loss: 1.1173 - val_loss: 0.5066\n",
            "Epoch 68/500\n",
            "37/37 - 0s - loss: 1.5163 - val_loss: 4.3292\n",
            "Epoch 69/500\n",
            "37/37 - 0s - loss: 1.4033 - val_loss: 2.6629\n",
            "Epoch 70/500\n",
            "37/37 - 0s - loss: 1.2214 - val_loss: 4.8213\n",
            "Epoch 71/500\n",
            "37/37 - 0s - loss: 1.0070 - val_loss: 5.7134\n",
            "Epoch 72/500\n",
            "37/37 - 0s - loss: 0.9992 - val_loss: 1.9134\n",
            "Epoch 73/500\n",
            "37/37 - 0s - loss: 1.1199 - val_loss: 3.8305\n",
            "Epoch 74/500\n",
            "37/37 - 0s - loss: 0.6874 - val_loss: 5.0132\n",
            "Epoch 75/500\n",
            "37/37 - 0s - loss: 1.2282 - val_loss: 5.2379\n",
            "Epoch 76/500\n",
            "37/37 - 0s - loss: 1.2889 - val_loss: 2.2740\n",
            "Epoch 77/500\n",
            "37/37 - 0s - loss: 1.3028 - val_loss: 3.2390\n",
            "Epoch 78/500\n",
            "37/37 - 0s - loss: 1.0394 - val_loss: 5.8614\n",
            "Epoch 79/500\n",
            "37/37 - 0s - loss: 0.9292 - val_loss: 6.3405\n",
            "Epoch 80/500\n",
            "37/37 - 0s - loss: 0.8844 - val_loss: 3.8399\n",
            "Epoch 81/500\n",
            "37/37 - 0s - loss: 0.8824 - val_loss: 3.0632\n",
            "Epoch 82/500\n",
            "37/37 - 0s - loss: 0.8514 - val_loss: 3.4483\n",
            "Epoch 83/500\n",
            "37/37 - 0s - loss: 1.1350 - val_loss: 4.2415\n",
            "Epoch 84/500\n",
            "37/37 - 0s - loss: 0.8598 - val_loss: 3.5317\n",
            "Epoch 85/500\n",
            "37/37 - 0s - loss: 0.8083 - val_loss: 5.6510\n",
            "Epoch 86/500\n",
            "37/37 - 0s - loss: 0.8295 - val_loss: 5.2102\n",
            "Epoch 87/500\n",
            "37/37 - 0s - loss: 0.9905 - val_loss: 4.1312\n",
            "Epoch 88/500\n",
            "37/37 - 0s - loss: 0.8253 - val_loss: 4.1596\n",
            "Epoch 89/500\n",
            "37/37 - 0s - loss: 0.7452 - val_loss: 3.9100\n",
            "Epoch 90/500\n",
            "37/37 - 0s - loss: 0.7895 - val_loss: 7.3022\n",
            "Epoch 91/500\n",
            "37/37 - 0s - loss: 0.8646 - val_loss: 5.7806\n",
            "Epoch 92/500\n",
            "37/37 - 0s - loss: 0.7999 - val_loss: 5.0500\n",
            "Epoch 93/500\n",
            "37/37 - 0s - loss: 0.7373 - val_loss: 7.2933\n",
            "Epoch 94/500\n",
            "37/37 - 0s - loss: 0.6791 - val_loss: 4.0737\n",
            "Epoch 95/500\n",
            "37/37 - 0s - loss: 1.1614 - val_loss: 5.9919\n",
            "Epoch 96/500\n",
            "37/37 - 0s - loss: 0.7824 - val_loss: 2.6641\n",
            "Epoch 97/500\n",
            "37/37 - 0s - loss: 0.7212 - val_loss: 4.0433\n",
            "Epoch 98/500\n",
            "37/37 - 0s - loss: 0.7128 - val_loss: 5.9363\n",
            "Epoch 99/500\n",
            "37/37 - 0s - loss: 0.7825 - val_loss: 6.4119\n",
            "Epoch 100/500\n",
            "37/37 - 0s - loss: 0.8656 - val_loss: 2.9818\n",
            "Epoch 101/500\n",
            "37/37 - 0s - loss: 0.9567 - val_loss: 1.9180\n",
            "Epoch 102/500\n",
            "37/37 - 0s - loss: 0.6882 - val_loss: 5.3751\n",
            "Epoch 103/500\n",
            "37/37 - 0s - loss: 0.5483 - val_loss: 3.6258\n",
            "Epoch 104/500\n",
            "37/37 - 0s - loss: 0.7828 - val_loss: 4.1964\n",
            "Epoch 105/500\n",
            "37/37 - 0s - loss: 0.6338 - val_loss: 3.8846\n",
            "Epoch 106/500\n",
            "37/37 - 0s - loss: 0.8132 - val_loss: 8.5342\n",
            "Epoch 107/500\n",
            "37/37 - 0s - loss: 0.8692 - val_loss: 6.0168\n",
            "Epoch 108/500\n",
            "37/37 - 0s - loss: 0.5905 - val_loss: 6.1982\n",
            "Epoch 109/500\n",
            "37/37 - 0s - loss: 0.6106 - val_loss: 4.1617\n",
            "Epoch 110/500\n",
            "37/37 - 0s - loss: 0.5802 - val_loss: 4.6413\n",
            "Epoch 111/500\n",
            "37/37 - 0s - loss: 0.6590 - val_loss: 3.4344\n",
            "Epoch 112/500\n",
            "37/37 - 0s - loss: 0.5787 - val_loss: 7.4300\n",
            "Epoch 113/500\n",
            "37/37 - 0s - loss: 0.5690 - val_loss: 3.1290\n",
            "Epoch 114/500\n",
            "37/37 - 0s - loss: 0.5381 - val_loss: 6.2718\n",
            "Epoch 115/500\n",
            "37/37 - 0s - loss: 0.5262 - val_loss: 3.0180\n",
            "Epoch 116/500\n",
            "37/37 - 0s - loss: 0.6822 - val_loss: 4.8568\n",
            "Epoch 117/500\n",
            "37/37 - 0s - loss: 0.8288 - val_loss: 7.2361\n",
            "Epoch 118/500\n",
            "37/37 - 0s - loss: 0.6348 - val_loss: 6.6452\n",
            "Epoch 119/500\n",
            "37/37 - 0s - loss: 0.6642 - val_loss: 3.5995\n",
            "Epoch 120/500\n",
            "37/37 - 0s - loss: 0.5740 - val_loss: 5.0213\n",
            "Epoch 121/500\n",
            "37/37 - 0s - loss: 0.4356 - val_loss: 6.2091\n",
            "Epoch 122/500\n",
            "37/37 - 0s - loss: 0.5190 - val_loss: 3.7404\n",
            "Epoch 123/500\n",
            "37/37 - 0s - loss: 0.4582 - val_loss: 3.9749\n",
            "Epoch 124/500\n",
            "37/37 - 0s - loss: 0.4883 - val_loss: 5.1558\n",
            "Epoch 125/500\n",
            "37/37 - 0s - loss: 0.3717 - val_loss: 5.9616\n",
            "Epoch 126/500\n",
            "37/37 - 0s - loss: 0.5019 - val_loss: 8.2624\n",
            "Epoch 127/500\n",
            "37/37 - 0s - loss: 0.5279 - val_loss: 4.8935\n",
            "Epoch 128/500\n",
            "37/37 - 0s - loss: 0.4719 - val_loss: 7.7198\n",
            "Epoch 129/500\n",
            "37/37 - 0s - loss: 0.4217 - val_loss: 5.2405\n",
            "Epoch 130/500\n",
            "37/37 - 0s - loss: 0.3742 - val_loss: 5.0253\n",
            "Epoch 131/500\n",
            "37/37 - 0s - loss: 0.7199 - val_loss: 5.5594\n",
            "Epoch 132/500\n",
            "37/37 - 0s - loss: 0.3480 - val_loss: 5.9991\n",
            "Epoch 133/500\n",
            "37/37 - 0s - loss: 0.4807 - val_loss: 4.0602\n",
            "Epoch 134/500\n",
            "37/37 - 0s - loss: 0.3641 - val_loss: 3.5013\n",
            "Epoch 135/500\n",
            "37/37 - 0s - loss: 0.3455 - val_loss: 6.3413\n",
            "Epoch 136/500\n",
            "37/37 - 0s - loss: 0.4118 - val_loss: 6.3449\n",
            "Epoch 137/500\n",
            "37/37 - 0s - loss: 0.3279 - val_loss: 6.8265\n",
            "Epoch 138/500\n",
            "37/37 - 0s - loss: 0.4585 - val_loss: 6.6617\n",
            "Epoch 139/500\n",
            "37/37 - 0s - loss: 0.2435 - val_loss: 6.0598\n",
            "Epoch 140/500\n",
            "37/37 - 0s - loss: 0.3319 - val_loss: 6.9661\n",
            "Epoch 141/500\n",
            "37/37 - 0s - loss: 0.3818 - val_loss: 6.0375\n",
            "Epoch 142/500\n",
            "37/37 - 0s - loss: 0.4690 - val_loss: 3.7993\n",
            "Epoch 143/500\n",
            "37/37 - 0s - loss: 0.2952 - val_loss: 4.2183\n",
            "Epoch 144/500\n",
            "37/37 - 0s - loss: 0.3681 - val_loss: 5.2450\n",
            "Epoch 145/500\n",
            "37/37 - 0s - loss: 0.2823 - val_loss: 4.5783\n",
            "Epoch 146/500\n",
            "37/37 - 0s - loss: 0.2958 - val_loss: 7.7519\n",
            "Epoch 147/500\n",
            "37/37 - 0s - loss: 0.3581 - val_loss: 4.4908\n",
            "Epoch 148/500\n",
            "37/37 - 0s - loss: 0.3365 - val_loss: 3.9604\n",
            "Epoch 149/500\n",
            "37/37 - 0s - loss: 0.3346 - val_loss: 8.7708\n",
            "Epoch 150/500\n",
            "37/37 - 0s - loss: 0.3026 - val_loss: 4.6919\n",
            "Epoch 151/500\n",
            "37/37 - 0s - loss: 0.3504 - val_loss: 2.8383\n",
            "Epoch 152/500\n",
            "37/37 - 0s - loss: 0.4010 - val_loss: 3.8949\n",
            "Epoch 153/500\n",
            "37/37 - 0s - loss: 0.4280 - val_loss: 5.6087\n",
            "Epoch 154/500\n",
            "37/37 - 0s - loss: 0.4503 - val_loss: 4.2605\n",
            "Epoch 155/500\n",
            "37/37 - 0s - loss: 0.3397 - val_loss: 4.4078\n",
            "Epoch 156/500\n",
            "37/37 - 0s - loss: 0.2325 - val_loss: 5.3561\n",
            "Epoch 157/500\n",
            "37/37 - 0s - loss: 0.2949 - val_loss: 6.1699\n",
            "Epoch 158/500\n",
            "37/37 - 0s - loss: 0.2530 - val_loss: 5.0693\n",
            "Epoch 159/500\n",
            "37/37 - 0s - loss: 0.2556 - val_loss: 3.4554\n",
            "Epoch 160/500\n",
            "37/37 - 0s - loss: 0.2007 - val_loss: 4.0040\n",
            "Epoch 161/500\n",
            "37/37 - 0s - loss: 0.3114 - val_loss: 9.3881\n",
            "Epoch 162/500\n",
            "37/37 - 0s - loss: 0.4685 - val_loss: 7.0120\n",
            "Epoch 163/500\n",
            "37/37 - 0s - loss: 0.2617 - val_loss: 5.7281\n",
            "Epoch 164/500\n",
            "37/37 - 0s - loss: 0.3046 - val_loss: 4.2938\n",
            "Epoch 165/500\n",
            "37/37 - 0s - loss: 0.2947 - val_loss: 4.6923\n",
            "Epoch 166/500\n",
            "37/37 - 0s - loss: 0.2893 - val_loss: 6.4811\n",
            "Epoch 167/500\n",
            "37/37 - 0s - loss: 0.2311 - val_loss: 7.2606\n",
            "Epoch 168/500\n",
            "37/37 - 0s - loss: 0.2468 - val_loss: 3.5938\n",
            "Epoch 169/500\n",
            "37/37 - 0s - loss: 0.3357 - val_loss: 6.8863\n",
            "Epoch 170/500\n",
            "37/37 - 0s - loss: 0.3509 - val_loss: 6.7317\n",
            "Epoch 171/500\n",
            "37/37 - 0s - loss: 0.2510 - val_loss: 4.8889\n",
            "Epoch 172/500\n",
            "37/37 - 0s - loss: 0.2359 - val_loss: 8.3005\n",
            "Epoch 173/500\n",
            "37/37 - 0s - loss: 0.2940 - val_loss: 5.4872\n",
            "Epoch 174/500\n",
            "37/37 - 0s - loss: 0.2154 - val_loss: 5.8940\n",
            "Epoch 175/500\n",
            "37/37 - 0s - loss: 0.2376 - val_loss: 6.8798\n",
            "Epoch 176/500\n",
            "37/37 - 0s - loss: 0.3489 - val_loss: 7.2209\n",
            "Epoch 177/500\n",
            "37/37 - 0s - loss: 0.3436 - val_loss: 6.1349\n",
            "Epoch 178/500\n",
            "37/37 - 0s - loss: 0.4096 - val_loss: 3.7270\n",
            "Epoch 179/500\n",
            "37/37 - 0s - loss: 0.1866 - val_loss: 5.8645\n",
            "Epoch 180/500\n",
            "37/37 - 0s - loss: 0.2071 - val_loss: 4.7391\n",
            "Epoch 181/500\n",
            "37/37 - 0s - loss: 0.2787 - val_loss: 3.5844\n",
            "Epoch 182/500\n",
            "37/37 - 0s - loss: 0.3193 - val_loss: 5.8076\n",
            "Epoch 183/500\n",
            "37/37 - 0s - loss: 0.2346 - val_loss: 9.9715\n",
            "Epoch 184/500\n",
            "37/37 - 0s - loss: 0.3752 - val_loss: 7.0824\n",
            "Epoch 185/500\n",
            "37/37 - 0s - loss: 0.2406 - val_loss: 5.7791\n",
            "Epoch 186/500\n",
            "37/37 - 0s - loss: 0.1802 - val_loss: 5.0708\n",
            "Epoch 187/500\n",
            "37/37 - 0s - loss: 0.4316 - val_loss: 5.7601\n",
            "Epoch 188/500\n",
            "37/37 - 0s - loss: 0.2680 - val_loss: 4.0158\n",
            "Epoch 189/500\n",
            "37/37 - 0s - loss: 0.3045 - val_loss: 5.7866\n",
            "Epoch 190/500\n",
            "37/37 - 0s - loss: 0.6484 - val_loss: 7.3754\n",
            "Epoch 191/500\n",
            "37/37 - 0s - loss: 0.2324 - val_loss: 3.0858\n",
            "Epoch 192/500\n",
            "37/37 - 0s - loss: 0.3002 - val_loss: 3.2048\n",
            "Epoch 193/500\n",
            "37/37 - 0s - loss: 0.4061 - val_loss: 5.5993\n",
            "Epoch 194/500\n",
            "37/37 - 0s - loss: 0.2370 - val_loss: 4.0095\n",
            "Epoch 195/500\n",
            "37/37 - 0s - loss: 0.3327 - val_loss: 5.3847\n",
            "Epoch 196/500\n",
            "37/37 - 0s - loss: 0.2070 - val_loss: 3.9705\n",
            "Epoch 197/500\n",
            "37/37 - 0s - loss: 0.2021 - val_loss: 3.8816\n",
            "Epoch 198/500\n",
            "37/37 - 0s - loss: 0.2281 - val_loss: 6.2227\n",
            "Epoch 199/500\n",
            "37/37 - 0s - loss: 0.2536 - val_loss: 5.1694\n",
            "Epoch 200/500\n",
            "37/37 - 0s - loss: 0.1458 - val_loss: 5.2491\n",
            "Epoch 201/500\n",
            "37/37 - 0s - loss: 0.1824 - val_loss: 5.7820\n",
            "Epoch 202/500\n",
            "37/37 - 0s - loss: 0.1660 - val_loss: 7.3098\n",
            "Epoch 203/500\n",
            "37/37 - 0s - loss: 0.2486 - val_loss: 6.3740\n",
            "Epoch 204/500\n",
            "37/37 - 0s - loss: 0.1762 - val_loss: 7.3811\n",
            "Epoch 205/500\n",
            "37/37 - 0s - loss: 0.1948 - val_loss: 5.8738\n",
            "Epoch 206/500\n",
            "37/37 - 0s - loss: 0.2443 - val_loss: 4.9514\n",
            "Epoch 207/500\n",
            "37/37 - 0s - loss: 0.1535 - val_loss: 2.8259\n",
            "Epoch 208/500\n",
            "37/37 - 0s - loss: 0.2880 - val_loss: 5.4386\n",
            "Epoch 209/500\n",
            "37/37 - 0s - loss: 0.1790 - val_loss: 6.9118\n",
            "Epoch 210/500\n",
            "37/37 - 0s - loss: 0.2408 - val_loss: 3.5411\n",
            "Epoch 211/500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-e9f72e347262>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhas_cv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdsuJyTsQvrk",
        "outputId": "646ef14d-4f8f-43b6-cd6c-2632a36a24e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "names = list(map(lambda x: x.__class__.__name__, classifiers))\n",
        "# names.append(\"Neural network\")\n",
        "models = pd.DataFrame({\n",
        "    'Models': names,\n",
        "    'Train-accuracy': train_scores,\n",
        "    'Validation-accuracy': test_scores \n",
        "})\n",
        "models.sort_values(by='Validation-accuracy')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Models</th>\n",
              "      <th>Train-accuracy</th>\n",
              "      <th>Validation-accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DecisionTreeRegressor</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RandomForestRegressor</td>\n",
              "      <td>0.0529</td>\n",
              "      <td>0.0529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BayesianRidge</td>\n",
              "      <td>0.0984</td>\n",
              "      <td>0.0984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>KNeighborsRegressor</td>\n",
              "      <td>0.2026</td>\n",
              "      <td>0.2026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SVR</td>\n",
              "      <td>0.2751</td>\n",
              "      <td>0.2751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LinearSVR</td>\n",
              "      <td>0.3021</td>\n",
              "      <td>0.3021</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Models Train-accuracy Validation-accuracy\n",
              "4  DecisionTreeRegressor            0.0                 0.0\n",
              "3  RandomForestRegressor         0.0529              0.0529\n",
              "0          BayesianRidge         0.0984              0.0984\n",
              "5    KNeighborsRegressor         0.2026              0.2026\n",
              "1                    SVR         0.2751              0.2751\n",
              "2              LinearSVR         0.3021              0.3021"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 597
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEZ6bur0RqIq"
      },
      "source": [
        "def getSubmission (value):\n",
        "  for clf in classifiers:\n",
        "    if (clf.__class__.__name__ == value):\n",
        "      print(clf.__class__.__name__)\n",
        "      predictions = clf.predict(test_data_input)\n",
        "  return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i4sOSrydoY5"
      },
      "source": [
        "def getNNSubmission ():\n",
        "  pred = model.predict(test_data_input)\n",
        "  return pred.flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v8h7EAowhOH"
      },
      "source": [
        "# predictions = getSubmission('BayesianRidge')\n",
        "predictions = getNNSubmission()\n",
        "\n",
        "output = pd.DataFrame({'Id': test_df.Id, 'SalePrice': np.expm1(predictions)})\n",
        "\n",
        "output.to_csv('my_submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GP4ceTtwEN3Y"
      },
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "scaler= RobustScaler()\n",
        "# transform \"x_train\"\n",
        "train_input = scaler.fit_transform(train_input)\n",
        "# transform \"x_test\"\n",
        "if (has_cv):\n",
        "  cv_input = scaler.transform(cv_input)\n",
        "#Transform the test set\n",
        "test_data_input = scaler.transform(test_data_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KcHnBUah_RB",
        "outputId": "c32c4a05-a426-4e85-954a-c3587c359e77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "ridge=Ridge()\n",
        "parameters= {'alpha':[x for x in range(1,101)]}\n",
        "\n",
        "ridge_reg = GridSearchCV(estimator=ridge, param_grid=parameters, scoring='neg_mean_squared_error', cv=15)\n",
        "ridge_reg.fit(train_input,train_label)\n",
        "print(\"The best value of Alpha is: \",ridge_reg.best_params_)\n",
        "print(\"The best score achieved with Alpha=11 is: \",math.sqrt(-ridge_reg.best_score_))\n",
        "ridge_pred=math.sqrt(-ridge_reg.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The best value of Alpha is:  {'alpha': 9}\n",
            "The best score achieved with Alpha=11 is:  0.11589743355970451\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOXvx2cJQnom",
        "outputId": "6c25baef-08d1-46ff-f10e-e71f7fa70cc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "\n",
        "ridge_mod=Ridge(alpha=11)\n",
        "ridge_mod.fit(train_input,train_label)\n",
        "y_pred_train=ridge_mod.predict(train_input)\n",
        "\n",
        "print('Root Mean Square Error train = ' + str(math.sqrt(mean_squared_error(train_label, y_pred_train))))\n",
        "if (has_cv):\n",
        "  y_pred_cv = ridge_mod.predict(cv_input)\n",
        "  print('Root Mean Square Error test = ' + str(math.sqrt(mean_squared_error(cv_label, y_pred_cv))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Root Mean Square Error train = 0.10009675674419488\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0yniOuVWeEp",
        "outputId": "a0a087ea-1d3f-44da-8e82-f45dbd49c460",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        }
      },
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "parameters= {'alpha':[0.0001,0.0009,0.001,0.002,0.003,0.01,0.1,1,10,100]}\n",
        "\n",
        "lasso=Lasso()\n",
        "lasso_reg=GridSearchCV(lasso, param_grid=parameters, scoring='neg_mean_squared_error', cv=15)\n",
        "lasso_reg.fit(train_input,train_label)\n",
        "\n",
        "print('The best value of Alpha is: ',lasso_reg.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08305955171536539, tolerance: 0.021675117547308585\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.09122581256003492, tolerance: 0.02174785009373819\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4532840776144358, tolerance: 0.02182417303907677\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08875920799183135, tolerance: 0.0214732486632979\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08803013941937365, tolerance: 0.02139340794302057\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4193258463587828, tolerance: 0.02152250846597941\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0821260045933645, tolerance: 0.021316938834001445\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08558493600971318, tolerance: 0.021284252768371106\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.09008481114742395, tolerance: 0.022064241209339905\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08796682585490423, tolerance: 0.021692525464120857\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.09203699117611386, tolerance: 0.02160376747374204\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4872264813462177, tolerance: 0.022099902395100172\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.087448107675689, tolerance: 0.021756235733956464\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08753630190087769, tolerance: 0.021618553721326008\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08653901400483655, tolerance: 0.021767080343942712\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The best value of Alpha is:  {'alpha': 0.0009}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyE75jD6W-RV",
        "outputId": "3c1ebbc0-276c-4c76-c073-f52f90f2fedd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "lasso_mod=Lasso(alpha=0.0009)\n",
        "lasso_mod.fit(train_input,train_label)\n",
        "y_lasso_train=lasso_mod.predict(train_input)\n",
        "\n",
        "print('Root Mean Square Error train = ' + str(math.sqrt(mean_squared_error(train_label, y_lasso_train))))\n",
        "if (has_cv): \n",
        "  y_lasso_cv=lasso_mod.predict(cv_input)\n",
        "  print('Root Mean Square Error test = ' + str(math.sqrt(mean_squared_error(cv_label, y_lasso_cv))))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Root Mean Square Error train = 0.10778109879684361\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tg2vqyUznCrg"
      },
      "source": [
        "# from sklearn.linear_model import ElasticNetCV\n",
        "\n",
        "# alphas = [0.000542555]\n",
        "# l1ratio = [0.1, 0.3,0.5, 0.9, 0.95, 0.99, 1]\n",
        "\n",
        "# elastic_cv = ElasticNetCV(cv=5, max_iter=1e7, alphas=alphas,  l1_ratio=l1ratio)\n",
        "\n",
        "# elasticmod = elastic_cv.fit(train_input, train_label.ravel())\n",
        "# if (has_cv):\n",
        "#   ela_pred=elasticmod.predict(cv_input)\n",
        "#   print('Root Mean Square Error test = ' + str(math.sqrt(mean_squared_error(cv_label, ela_pred))))\n",
        "# print(elastic_cv.alpha_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oubAGoSxw34-"
      },
      "source": [
        "from xgboost.sklearn import XGBRegressor\n",
        "\n",
        "xgb= XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
        "             colsample_bynode=1, colsample_bytree=0.5, gamma=0,\n",
        "             importance_type='gain', learning_rate=0.01, max_delta_step=0,\n",
        "             max_depth=3, min_child_weight=0, missing=None, n_estimators=4000,\n",
        "             n_jobs=1, nthread=None, objective='reg:squarederror', random_state=0,\n",
        "             reg_alpha=0.0001, reg_lambda=0.01, scale_pos_weight=1, seed=None,\n",
        "             silent=None, subsample=1, verbosity=1)\n",
        "xgmod=xgb.fit(train_input,train_label)\n",
        "if (has_cv):\n",
        "  xg_pred=xgmod.predict(cv_input)\n",
        "  print('Root Mean Square Error test = ' + str(math.sqrt(mean_squared_error(cv_label, xg_pred))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScMa1Tw3xKM0"
      },
      "source": [
        "from sklearn.ensemble import VotingRegressor\n",
        "\n",
        "\n",
        "vote_mod = VotingRegressor([('Ridge', ridge_mod), ('Lasso', lasso_mod),\n",
        "                            ('XGBRegressor', xgb)])\n",
        "vote= vote_mod.fit(train_input,train_label.ravel())\n",
        "\n",
        "if (has_cv):\n",
        "  vote_pred=vote.predict(cv_input)\n",
        "  print('Root Mean Square Error test = ' + str(math.sqrt(mean_squared_error(cv_label, vote_pred))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0LybhxkxfGX"
      },
      "source": [
        "from mlxtend.regressor import StackingRegressor\n",
        "\n",
        "\n",
        "stregr = StackingRegressor(regressors=[ridge_mod, lasso_mod, vote_mod], \n",
        "                           meta_regressor=xgb, use_features_in_secondary=True\n",
        "                          )\n",
        "\n",
        "stack_mod=stregr.fit(train_input,train_label.ravel())\n",
        "if (has_cv):\n",
        "  stacking_pred=stack_mod.predict(cv_input)\n",
        "  print('Root Mean Square Error test = ' + str(math.sqrt(mean_squared_error(cv_label, stacking_pred))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPzdEQ7n-w7E"
      },
      "source": [
        "if (has_cv):\n",
        "  vote_testcv = vote_mod.predict(cv_input)\n",
        "  #StackingRegressor to predict the final Test\n",
        "  stack_testcv = stregr.predict(cv_input)\n",
        "  \n",
        "  #LassoRegressor to predict the final Test\n",
        "  lasso_testcv = lasso_mod.predict(cv_input)\n",
        "  \n",
        "  \n",
        "  cvcombo = (0.2*vote_testcv+0.6*stack_testcv+0.2*lasso_testcv)\n",
        "  print(str(math.sqrt(mean_squared_error(cv_label, cvcombo))))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLTnGSujxmNh"
      },
      "source": [
        "#VotingRegressor to predict the final Test\n",
        "vote_test = vote_mod.predict(test_data_input)\n",
        "final1=np.expm1(vote_test)\n",
        "\n",
        "#StackingRegressor to predict the final Test\n",
        "stack_test = stregr.predict(test_data_input)\n",
        "final2=np.expm1(stack_test)\n",
        "\n",
        "#LassoRegressor to predict the final Test\n",
        "lasso_test = lasso_mod.predict(test_data_input)\n",
        "final3=np.expm1(lasso_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeSARmnGWW8C"
      },
      "source": [
        "# y_sub = lasso_mod.predict(test_data_input)\n",
        "y_sub = (0.2*final1+0.6*final2+0.2*final3)\n",
        "\n",
        "output = pd.DataFrame({'Id': test_df.Id, 'SalePrice': y_sub})\n",
        "\n",
        "output.to_csv('my_submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}